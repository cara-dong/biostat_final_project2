---
title: "Data Exploration"
author: "Manye Dong"
date: "2023-11-28"
output: github_document
---

## Goal: Predict the risk of death based on features 1-14
```{r message = FALSE, echo= FALSE}
library(tidyverse)
library(corrplot)
library(leaps)
library(glmnet)
library(caret)


options(
  ggplot2.continuous.colour = "viridis", 
  ggplots.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_disrete = scale_fill_viridis_d


```


```{r}
# import data and data cleaning
bc_data = read.csv("./Project_2_data.csv") |>
  janitor::clean_names() |> 
  na.omit()
```

### Data summary 
```{r}
# include a descriptive table with summary statistics for all variables

# continuous data
conti_var = c("age", "tumor_size", "regional_node_examined","reginol_node_positive", "survival_months")
bc_data |>
  select(all_of(conti_var)) |>
  summary() |>
  knitr::kable()

# discrete data count number of distinct variables


discre_var <- c("race", "marital_status", "t_stage", "n_stage", "x6th_stage", "differentiate", "grade", "a_stage", "estrogen_status", "progesterone_status", "status")

# Function to create a summary table for each variable
summary_table = function(variable) {
  counts = table(bc_data[[variable]])
  summary_df = data.frame(
    Variable = rep(variable, length(counts)),
    Value = paste(variable, names(counts), sep = "_"),
    Count = as.vector(counts)
  )
  return(summary_df)
}

summary_tables = lapply(discre_var, summary_table)
combined_summary = do.call(rbind, summary_tables) |>
  knitr::kable()
print(combined_summary)
```

### Outliers
```{r}
Q1 <- quantile(bc_data$survival_months, 0.25)
Q3 <- quantile(bc_data$survival_months, 0.75)
IQR <- Q3 - Q1

lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR

outliers <- bc_data |> filter((survival_months < lower_bound) | (survival_months > upper_bound))

bc_data <- anti_join(bc_data, outliers, by = c(colnames(bc_data)))
```


### Survial Months distribution 
```{r}
# explore the distribution of the outcome and consider potential transformations if necessary
# look at the original distribution of survival months
hist(bc_data$survival_months, main = "Distribution of survival months", xlab = "Survival Month")

#try different transformation 
log_survival = log(bc_data$survival_months)
hist(log_survival, main = "Distribution of log_transformed survival months", xlab = "log-transformed survival months")

sqrt_survival = sqrt(bc_data$survival_months)
hist(sqrt_survival, main = "Distribution of sqrt(survival months)", xlab = "sqrt(survival months)")

sq_survival = (bc_data$survival_months^2)
hist(sq_survival, main = "Distribution of square(survival months)", xlab = "square(survival months)")

iv_survival = (1/bc_data$survival_months)
hist(iv_survival, main = "Distribution of inverse(survival months)", xlab = "inverse(survival months)", xlim = c(0,0.1),breaks=100)
```

### Convert categorical data to factor
```{r}
bc_data = 
  bc_data |>
  mutate(
    race = factor(race, labels = c("1", "2", "3"), levels = c("Black", "White", "Other")),
    marital_status = factor(marital_status, labels = c("1", "2", "3","4","5"),levels = c("Divorced", "Married", "Separated", "Single ", "Widowed")),
    t_stage = factor(t_stage, labels = c("1", "2", "3","4"),levels = c("T1", "T2", "T3", "T4")),
    n_stage = factor(n_stage, labels = c("1","2","3"),levels = c("N1","N2", "N3")),
    x6th_stage = factor(x6th_stage, labels = c("1", "2", "3","4","5"),levels = c("IIA","IIB","IIIA","IIIB","IIIC")),
    differentiate = factor(differentiate, labels = c("1", "2", "3","4"),levels = c("Moderately differentiated","Poorly differentiated","Undifferentiated","Well differentiated")),
    grade = factor(grade, labels = c("1", "2", "3","4"),levels = c("1","2","3"," anaplastic; Grade IV")),
    a_stage = factor(a_stage, labels = c("1","2"),levels = c("Distant","Regional")),
    estrogen_status = factor(estrogen_status, labels = c("0","1"),levels = c("Negative","Positive")),
    progesterone_status = factor(progesterone_status, labels = c("0","1"),levels = c("Negative","Positive")),
    status = factor(status, labels = c("0","1"),levels = c("Dead","Alive"))
    ) |> 
  rename(regional_node_positive = reginol_node_positive) 
```


## Look at data interaction and collinearity
```{r}
# Pairwise interaction and Correlation plot
bc_data |> 
  select(-status, -survival_months) |> 
  pairs()


cor_matrix <- 
  bc_data |> 
  select(-status, -survival_months) |> 
  mutate(across(where(is.factor), as.numeric)) |> 
  cor()

print(cor_matrix, digits = 3)

corrplot(cor_matrix, type = "upper", diag = FALSE, tl.cex = 0.5, tl.srt = 45)
```

```{r}
# boxplots for each variable
par(mfrow = c(2,3))

boxplot(bc_data$survival_months, main = "survival_months")
boxplot(bc_data$age, main = "age")
boxplot(bc_data$race, main = "race")
boxplot(bc_data$marital_status, main = "marital_status")
boxplot(bc_data$t_stage, main = "t_stage")
boxplot(bc_data$n_stage, main = "n_stage")

par(mfrow = c(2,4))
boxplot(bc_data$x6th_stage, main = "x6th_stage")
boxplot(bc_data$differentiate, main = "differentiate")
boxplot(bc_data$a_stage, main = "a_stage")
boxplot(bc_data$tumor_size, main = "tumor_size")
boxplot(bc_data$estrogen_status, main = "estrogen_status")
boxplot(bc_data$progesterone_status, main = "progesterone_status")
boxplot(bc_data$regional_node_examined, main = "regional_node_examined")
boxplot(bc_data$regional_node_positive, main = "regional_node_positive")
```

## Model and MLR selections
### MLR with all predictors
```{r}
mult.fit = lm(survival_months ~ ., data = bc_data)

#logit_fit=glm(status ~ .-survival_months,family="binomial",data=bc_data)
#summary(logit_fit)


summary(mult.fit)

# QQ plot showing datafit 
plot(mult.fit)
# residual vs. leverage plot
plot(mult.fit, which = 4)
```
Looks like doesn't need a transformation on the outcome survival months.

Use box-cox transformation to double-check if we need to make transformations.
```{r message=FALSE, warning=FALSE}
# boxcox(mult.fit)
```

Since lambda approaches 1 and its 95% CI lies close to 1, it suggests that we do not need to make any transformation.

Based on Cook's distance, we will investigate the three influential points:
```{r}
view_influential = bc_data[c(278, 1553, 1584), ]
view_influential
```

After investigation, it looks like these three points are not negatively impacting the results. So, we will not remove them. They have a reason to be there.

### MLR reducing multicollinearity using correlation matrix
First, find the highly correlated pairs:
```{r}
new_df = bc_data |> mutate(across(where(is.factor), as.numeric))
```

```{r}
cor_matrix = cor(new_df[, c(colnames(new_df))])

# Find the pairs where correlation is greater than or equal to 0.7 but less than 1
high_cor_pairs = which(cor_matrix >= 0.7 & cor_matrix < 1, arr.ind = TRUE)

# Extract the variable names for these pairs
high_cor_var_pairs = data.frame(
  Var1 = rownames(cor_matrix)[high_cor_pairs[, 1]],
  Var2 = colnames(cor_matrix)[high_cor_pairs[, 2]],
  Correlation = cor_matrix[high_cor_pairs]
)

high_cor_var_pairs |> 
  knitr::kable(digits=4)
```

Remove the one with lower correlation with outcome in every pair:
```{r}
cor_tumor = cor_matrix["survival_months", "tumor_size"]
cor_tstage = cor_matrix["survival_months", "t_stage"]

c(cor_tumor, cor_tstage)
```
Keep tumor_size.

```{r}
cor_tumor = cor_matrix["survival_months", "x6th_stage"]
cor_nstage = cor_matrix["survival_months", "n_stage"]
cor_regional = cor_matrix["survival_months", "regional_node_positive"]

c(cor_tumor, cor_nstage, cor_regional)
```
Keep tumor_size, delete the other two.

Fit the reduced model:
```{r}
reduced_df = bc_data |> select(-t_stage, -n_stage, -x6th_stage)
```

```{r}
reduced_model = lm(survival_months ~ ., data = reduced_df) 

summary(reduced_model) 
# |> broom::tidy() |> knitr::kable(digits=3)
```

Estrogen_status1 seems to be the most influential factor .

```{r}
plot(reduced_model)
```

Normality fit looks better at the left tail.

### Stepwise, Backward
```{r}
# backward regression 
#step_backward = step(mult.fit, direction='backward')

# Criteria based procedures. both direction: choose the model with the smallest AIC value
step_both = MASS::stepAIC(mult.fit, direction = "both", trace = FALSE) |>
  broom::tidy()

knitr::kable(step_both, digits = 3)
```

### LASSO
```{r}
# fit a LASSO with lambda = 1
# smaller lambda, tends to give large model (more predictors)

mat = makeX(bc_data[1:14])
```

```{r}
fit_LASSO = cv.glmnet(mat, bc_data$survival_months, alpha = 1)
plot(fit_LASSO)
```

```{r}
best_lambda = fit_LASSO$lambda.min
best_model = glmnet(mat, bc_data$survival_months, alpha=1, lambda=best_lambda)
coef(best_model)
```

```{r}
best_lambda
```

```{r}
fit_LASSO_logit = cv.glmnet(mat, bc_data$status, family="binomial")
plot(fit_LASSO_logit)
```

```{r}
coef(fit_LASSO_logit)
```


## Model Validation & Performance Evaluation

First, we will conduct a train-test split on bc_data:
```{r}
# train test split used for training and testing
# Set seed for reproducibility
set.seed(123)

# Split data into training and testing sets (80% train, 20% test)
train_indices <- sample(seq_len(nrow(bc_data)), 0.8 * nrow(bc_data))  # 80% train indices
train_data <- bc_data[train_indices, ]  # Training data
test_data <- bc_data[-train_indices, ]  # Testing data

# Separate predictor variables (train_x, test_x) and target variable (train_y, test_y)
train_x <- train_data[, -which(names(train_data) == "survival_months")]
train_y <- train_data$survival_months

test_x <- test_data[, -which(names(test_data) == "survival_months")]
test_y <- test_data$survival_months
```

### Test MLR w/ all predictors
```{r}
# Fit the MLR model on the training data
mult.fit <- lm(survival_months ~ ., data = train_data)

# Predict on the test data
predicted_test <- predict(mult.fit, newdata = test_data)

# Calculate evaluation metrics (e.g., Mean Squared Error, R-squared)
rmse <- sqrt(mean((predicted_test - test_data$survival_months)^2))
rsquared <- summary(mult.fit)$r.squared

rsquared
```

```{r}
mlr_summary <- summary(mult.fit)
adjusted_r_squared_mlr <- mlr_summary$adj.r.squared
adjusted_r_squared_mlr
```

We will also cross-validate MLR to double-check:
```{r}
# Define the number of folds for cross-validation
num_folds <- 5  # You can adjust the number of folds as needed

# Define the control parameters for cross-validation
ctrl <- trainControl(method = "cv", number = num_folds)

# Train the MLR model with k-fold cross-validation
mult.fit_cv <- train(survival_months ~ ., data = bc_data, method = "lm", trControl = ctrl)

# Get cross-validated performance metrics
cv_results <- mult.fit_cv$results
print(cv_results)
```
The RMSE and R-squared appear similar.


### Test MLR with reduced multicollinearity
```{r}
# Fit the MLR model on the training data
reduced_train = train_data |> select(-t_stage, n_stage, x6th_stage)
reduced_test = test_data |> select(-t_stage, n_stage, x6th_stage)
  
reduced_fit <- lm(survival_months ~ ., data = reduced_train)

# Predict on the test data
predicted_test <- predict(reduced_fit, newdata = reduced_test)

# Calculate evaluation metrics (e.g., Mean Squared Error, R-squared)
rmse <- sqrt(mean((predicted_test - reduced_test$survival_months)^2))
rsquared <- summary(reduced_fit)$r.squared

rsquared
```

```{r}
mlr_summary_reduced <- summary(reduced_model)
adjusted_r_squared_mlr_reduced <- mlr_summary_reduced$adj.r.squared
adjusted_r_squared_mlr_reduced
```

We will also cross-validate MLR to double-check:
```{r}
# Define the number of folds for cross-validation
num_folds <- 5  # You can adjust the number of folds as needed

# Define the control parameters for cross-validation
ctrl <- trainControl(method = "cv", number = num_folds)

# Train the MLR model with k-fold cross-validation
reduced_fit_cv <- train(survival_months ~ ., data = reduced_df, method = "lm", trControl = ctrl)

# Get cross-validated performance metrics
cv_results_reduced <- reduced_fit_cv$results
print(cv_results_reduced)
```

The RMSE and R-squared appear similar to that before cross-validation.

### Test Stepwise Regression Model
```{r}
# Create a named vector of coefficients
coefficients <- c(
  `(Intercept)` = 39.290750,
  a_stage = 3.426435, 
  estrogen_status = 3.744369, 
  status = 29.713666
)

# Extract the predictor names from the coefficients
selected_predictors <- names(coefficients)[-1]  # Exclude '(Intercept)'

# Construct the formula for the model
selected_formula <- reformulate(selected_predictors, response = "survival_months")

# Fit the MLR model using the selected predictors and coefficients
selected_model <- lm(selected_formula, data = train_data)  # Replace 'your_data' with your dataset

# View the summary of the model
summary(selected_model)
```

```{r}
# Predict on the test data
predicted_test <- predict(selected_model, newdata = test_data)

# Calculate evaluation metrics: RMSE, R-squared, and adjusted R-squared
actual_values <- test_data$survival_months  # Actual values from test data

# RMSE
rmse <- sqrt(mean((predicted_test - test_y)^2))

# R-squared
rsquared <- summary(selected_model)$r.squared

# Adjusted R-squared
num_predictors <- length(coef(selected_model)) - 1  # Number of predictors (excluding intercept)
n <- length(test_y)  # Total number of samples
adjusted_r_squared <- 1 - ((1 - rsquared) * (n - 1) / (n - num_predictors - 1))

cat("RMSE:", rmse, "\n")
cat("R-squared:", rsquared, "\n")
cat("Adjusted R-squared:", adjusted_r_squared, "\n")
```

### Test LASSO
```{r}
# Train LASSO model using the best lambda obtained from cross-validation
lasso_model <- glmnet(train_x, train_y, alpha = 1, lambda = best_lambda)
```

```{r}
# Predict using the validation data
predicted_val <- predict(lasso_model, newx = as.matrix(test_x))

# Calculate evaluation metrics (e.g., Mean Squared Error and R-squared)
rmse <- sqrt(mean((predicted_val - test_y)^2))
rsquared <- 1 - (sum((test_y - predicted_val)^2) / sum((test_y - mean(test_y))^2))
```

```{r}
# Calculate the residual sum of squares (RSS)
rss <- sum((predicted_val - test_y)^2)

# Get the number of predictors used in the LASSO model
num_predictors <- sum(coef(lasso_model) != 0) - 1  # Exclude intercept (-1)

# Get the total number of samples
n <- length(test_y)

# Calculate adjusted R-squared for LASSO model
r_squared <- 1 - (rss / ((n - num_predictors - 1) * var(test_y)))
adjusted_r_squared_lasso <- 1 - ((1 - r_squared) * (n - 1) / (n - num_predictors - 1))
```

```{r}
adjusted_r_squared_lasso
```

## The model we selected...

xxxx
The reasons behind: The crude, all-in-one MLR performs better than linear regression with LASSO regularization in terms of adjusted R-squared. all-predictor one compared with the reduced-predictor one?

## Additional: Logistic Regression
```{r}
# Fit logistic regression model
logistic_model <- glm(status ~ ., data = bc_data, family = "binomial")

# Summary of the logistic regression model
summary(logistic_model)

# Predict on the training set
predicted <- predict(logistic_model, type = "response")

# Display the predicted values
head(predicted)
```

Evaluate model performance on training set:
```{r}
library(caret)
library(pROC)

# Create the confusion matrix
conf_matrix <- confusionMatrix(as.factor(round(predicted)), as.factor(bc_data$status))

# Print the confusion matrix
print(conf_matrix)

# ROC curve and AUC
roc_curve <- roc(bc_data$status, predicted)
plot(roc_curve)
```

Use train-test split on logistic regression model to validate the model:
```{r}

```


## Additional: Compare performance for White vs Black groups
And can you improve the prediction performance gap btw these two groups for your model?
```{r}

```

